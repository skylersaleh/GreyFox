GREYFOX Instruction Set Architecture

**Overview**

Features:
    - 64bit integer and IEEE floating point
    - 32 General Purpose Registers + 4 Special Purpose Registers
    - atomics
    - supervisor calls
    - virtualization
    - software breakpoints
    - Coprocessor interface for Vector, Matrix, RT, Texture, AI, String Ops, DMA, encryption, etc. cores
    - C++ compliant memory model (HW maintains LD/ST logical ordering, HW cache coherency)
    - FP Special Functions (cos/sin/tan, sqrt, rsqrt, rcp)

Registers:
    i0-i15 Integer General Purpose Registers (uint64_t/int64_t)
    f0-f15 Floating Point General Purpose Registers (double)
    PC Program Counter (uint64_t), bit 0 is always 0
    SP Stack Pointer (uint64_t)
    LR Link Register (used to hide branch latency) (uint64_t)
    OFLOW Overflow Flag (bool)
    FPMODE uint8_t (floating point mode) [1:0 MODE [0: RNE 1: RTZ 2: R+Inf 3: R-Inf]] [2 flush denorms]

General Notes:
    - All opcodes that utilize PC (ie. PC relative load, relative branch) take PC after the opcode data but, before the immediate data. 
      For example branch_rel_imm.u16 2 will branch to the instruction immediately after the 2 bytes of immediate data for the branch_rel_imm.u16
      opcode. 

16b Fixed width instruction encoding for each instruction class:

    Short Branch Class:  [ 11:0 branch offset][15:12 op [Value 0xF]]
    Three Operand Class: [ 3:0 A  ] [ 7:4 B ] [ 11:8 C ] [ 15:12 op [Values 0xC-0xE]]
    Two Operand Class:   [ 3:0 A  ] [ 7:4 B ] [ 15:8 op [Values 0x10-0xBF]] 
    One Operand Class:   [ 3:0 A  ] [ 15:4 op2 [ Values 0x010-0x0FF]] 
    No operand Class:    [ 15:0 op2 [ Values 0x0000-0x00FF]] 

    All instructions are 2B aligned
    Total Opcode Space = 4 + 159+ 239 + 256 = 658 opcodes

**Opcode Listing**
Short Branch Class:
    F0XX-FFXX branch_relative               PC += sign_extend (opcode[11:0]*2)
Three Operand Class: [ 3:0 A  ] [ 7:4 B ] [ 11:8 C ] [ 15:12 op [Values 0xB-0xF]]
    EXXX fma a+=b*c (double)
    DXXX mad a+=b*c (int64_t)
Two Operand Class:   [ 3:0 A  ] [ 7:4 B ] [ 15:8 op [values 0x10-0xAF]] 
    int ops: (A=i0-i15), (B=i0-i15)
        10XX mov        A = B
        11XX add        A+=b; 
        12XX sub        A-=b; 
        13XX rsub       A = b-a
        14XX mul        A*=b
        15XX div.i64    A/=b
        16XX rdiv.i64   A=a/b
        17XX min.i64    A=min(a,b)
        18XX max.i64    A=max(a,b)
        19XX cmov       A = cnd ? A : B
        1AXX rcmov      A = cnd ? B : A
        1BXX abs.i64    A = abs(B)
        1CXX sign.i64   A = sign(B)
        1DXX neg.i64    A = -B
        1EXX inc        A = B+1
        1FXX dec        A = B-1
        20XX div.u64    A/=b
        21XX rdiv.u64   A=a/b
        22XX min.u64    A=min(a,b)
        23XX max.u64    A=max(a,b)
        24XX lsl        A<<=b
        25XX rlsl       A=(b<<a)
        26XX lsr        A>>=b
        27XX rlsr       A=(a>>b)
        28XX asr.i64    A=(int)a>>b
        29XX rasr.i64   A=(int)b>>a
        2AXX rotr       A = rotate_right(a,b)
        2BXX rotl       A = rotate_left(a,b)
        2CXX clz        A = count_leading_zeros(B)
        2DXX popcnt     A = bitcount(B)
        2EXX mod.i64    A = A%B
        2FXX mod.u64    A = (uint64_t)A%(uint64_t)B
        30XX addsl1     A += B<<1 \
        31XX addsl2     A += B<<2  | For array access
        32XX addsl3     A += B<<3 /
        33XX or         A |= b
        34XX xor        A ^= b
        35XX and        A &= b
        36XX not        A = ~B
        37XX bitreverse A = bitreverse(B)
        38xx unused
        39xx unused

    multi_pipeline_ops:
        3AXX ftoi A=(int64_t)B [A=i0-i15] [B=f0-f15]
        3BXX itof A=(double)B [A=f0-f15] [B=i0-i15]
        3CXX fmovi A = reinterpret_cast<uint64_t>(B) [A=i0-i15] [B=f0-f15]
        3DXX imovf A = reinterpret_cast<double>(B) [A=f0-f15] [B=i0-i15]
        3EXX f32movi A = (uint64_t)reinterpret_cast<uint32_t>((float)B) [A=i0-i15] [B=f0-f15]
        3FXX imovf32 A = (double)reinterpret_cast<float>((uint32_t)B) [A=f0-f15] [B=i0-i15]

    fp_ops: (A=f0-f15), (B=f0-f15)
        40XX mov.f   a=b
        41XX add.f   a+=b
        42XX sub.f   a-=b
        43XX rsub.f  a = b-a
        44XX mul.f   a*=b
        45XX div.f   a/=b
        46XX rdiv.f  b=a/b
        47XX min.f   a=min(a,b)
        48XX max.f   a=max(a,b)
        49XX cmov.f  A = cnd ? A : B
        4AXX rcmov.f A = cnd ? B : A
        4BXX abs.f   A = fabs(B)
        4CXX sign.f  A = fsign(B)
        4DXX neg.f   A = -B
        4EXX inc.f   A = B+1
        4FXX dec.f   A = B-1
        50XX round.f A = round(B)
        51XX floor.f A = floor(B)
        52XX ceil.f  A = ceil(B)
        53XX unused

    coprocessor_ops: [Used for extended instruction sets: ie. Vector, Matrix, RT, Texture, AI, String Ops, DMA, encryption]
        54XX cpcwr.2i  coprocessor( *(uint16_t*)(mem+PC),A,B);  PC+=2;   [A, B = i0-i15]
        55XX cpcwr.4i  coprocessor( *(uint32_t*)(mem+PC),A,B);  PC+=4;   [A, B = i0-i15]
        56XX cpcwr.8i  coprocessor( *(uint64_t*)(mem+PC),A,B);  PC+=8;   [A, B = i0-i15]
        57XX cpcwr.2f  coprocessor( *(uint16_t*)(mem+PC),A,B);  PC+=2;   [A, B = f0-f15]
        58XX cpcwr.4f  coprocessor( *(uint32_t*)(mem+PC),A,B);  PC+=4;   [A, B = f0-f15]
        59XX cpcwr.8f  coprocessor( *(uint64_t*)(mem+PC),A,B);  PC+=8;   [A, B = f0-f15]
        5AXX cpcrd.2i  A= coprocessor( *(uint16_t*)(mem+PC),A,B);  PC+=2;   [A, B = i0-i15]
        5BXX cpcrd.4i  A= coprocessor( *(uint32_t*)(mem+PC),A,B);  PC+=4;   [A, B = i0-i15]
        5CXX cpcrd.8i  A= coprocessor( *(uint64_t*)(mem+PC),A,B);  PC+=8;   [A, B = i0-i15]
        5DXX cpcrd.2f  A= coprocessor( *(uint16_t*)(mem+PC),A,B);  PC+=2;   [A, B = f0-f15]
        5EXX cpcrd.4f  A= coprocessor( *(uint32_t*)(mem+PC),A,B);  PC+=4;   [A, B = f0-f15]
        5FXX cpcrd.8f  A= coprocessor( *(uint64_t*)(mem+PC),A,B);  PC+=8;   [A, B = f0-f15]

    atomic_and_ld_ops:
        60XX ld.u8  A = *(uint8_t*)(mem+B)
        61XX ld.u16 A = *(uint16_t*)(mem+B)
        62XX ld.u32 A = *(uint32_t*)(mem+B)
        63XX ld.u64 A = *(uint64_t*)(mem+B)

        64XX ld.i8  A = *(int8_t*)(mem+B)
        65XX ld.i16 A = *(int16_t*)(mem+B)
        66XX ld.i32 A = *(int32_t*)(mem+B)
        67XX ld.i64 A = *(int64_t*)(mem+B)
        
        68XX ld.f16 A = *(half*)(mem+B)
        69XX ld.f32 A = *(float*)(mem+B)
        6AXX ld.f64 A = *(double*)(mem+B)

        6BXX atomic_args       IND = A; CMP = B (IND and CMP are only valid for the next instruction)
        6CXX atomic_cmpxchg    A = atomic_cmpxchg((uint32_t*)(mem+IND),CMP,B);
        6DXX atomic_cmpxchg    A = atomic_cmpxchg((uint64_t*)(mem+IND),CMP,B);
        6EXX atomic_xchg       A = atomic_xchg((uint32_t*)(mem+IND),B);
        6FXX atomic_xchg       A = atomic_xchg((uint64_t*)(mem+IND),B);

        70XX atomic_add        A = atomic_add((uint32_t*)(mem+IND),B);
        71XX atomic_add        A = atomic_add((uint64_t*)(mem+IND),B);
        72XX atomic_sub        A = atomic_sub((uint32_t*)(mem+IND),B);
        73XX atomic_sub        A = atomic_sub((uint64_t*)(mem+IND),B);
        74XX atomic_or         A = atomic_or ((uint32_t*)(mem+IND),B);
        75XX atomic_or         A = atomic_or ((uint64_t*)(mem+IND),B);
        76XX atomic_and        A = atomic_and((uint32_t*)(mem+IND),B);
        77XX atomic_and        A = atomic_and((uint64_t*)(mem+IND),B);
        78XX atomic_xor        A = atomic_xor((uint32_t*)(mem+IND),B);
        79XX atomic_xor        A = atomic_xor((uint64_t*)(mem+IND),B);
        7AXX atomic_min        A = atomic_min((uint32_t*)(mem+IND),B);
        7BXX atomic_min        A = atomic_min((uint64_t*)(mem+IND),B);
        7CXX atomic_max        A = atomic_max((uint32_t*)(mem+IND),B);
        7DXX atomic_max        A = atomic_max((uint64_t*)(mem+IND),B);

        7EXX store.u8  *(uint8_t*) (mem+A) = B
        7FXX store.u16 *(uint16_t*)(mem+A) = B
        80XX store.u32 *(uint32_t*)(mem+A) = B
        81XX store.u64 *(uint64_t*)(mem+A) = B
        82XX store.f16 *(half*)(mem+A)   = B
        83XX store.f32 *(float*)(mem+A)  = B
        84XX store.f64 *(double*)(mem+A) = B
  

    Compare Ops [0x9XXX-0xCXXX]
        Compare ops may come with an additional immediate called an extended compare command that can issue a branch, call, or return based
        on the result of the comparison operation. An assembly mnemonic for a compare instruction is contructed by combining the comparison 
        operation performed and the name of the operation named by th extended command.
        So, for example. 
            eq.f A, B will compute A = A == B
            less.i64.branch_rel_imm.i16 A, B, -100  will compute   if(A<B)PC+=-100 
            equal_zero.call_rel.i32 A, B, 0x32404885 will computeif(A==0)call_rel(0x32404885);

        Bits [15:12] describe the size of the data for the extended compare command (treated as an immediate in the instruction stream).
            9XXX no extended branch/move command A = A cmp B. 
            AXXX XXXX 2 Byte extended branch/move command after compare instruction bytes
                AXXX 0000 "return"                           if(A cmp B){PC = LR; SP-=8; LR=mem[SP]}
                AXXX 0001 - AXXX 7FFF "call_rel_imm.i16"     if(A cmp B){mem[SP]=LR; LR=PC+2; SP+=8; PC +=(int16_t)(imm[14:0]*2);}
                AXXX 8000 "svc_return"                       if(A cmp B){svc_return;}
                AXXX 8001 - AXXX FFFF "branch_rel_imm.i16"   if(A cmp B){PC +=(int16_t)(imm[14:0]*2);}
            BXXX XXXX XXXX 4 Byte extended branch/move command after compare instruction bytes
                BXXX 0000 0000 "hvc_return"                            if(A cmp B){hvc_return;}
                BXXX 0000 0001 - BXXX 7FFF FFFF "call_rel_imm.i32"     if(A cmp B){mem[SP]=LR; LR=PC+2; SP+=8; PC +=(int32_t)(imm[30:0]*2);}
                BXXX 8000 0000 unused
                BXXX 8000 0001 - BXXX FFFF FFFF "branch_rel_imm.i32"   if(A cmp B){PC +=(int32_t)(imm[30:0]*2);}
            CXXX XXXX XXXX XXXX XXXX 8 Byte extended branch/move command after compare instruction bytes
                CXXX 0000 0000 0000 0000 unused
                CXXX 0000 0000 0000 0001 - CXXX 7FFF FFFF FFFF FFFF "call_rel_imm.i64"     if(A cmp B){mem[SP]=LR; LR=PC+2; SP+=8; PC +=(int64_t)(imm[62:0]*2);}
                CXXX 8000 0000 0000 0000 unused
                CXXX 8000 0000 0000 0001 - CXXX FFFF FFFF FFFF FFFF "branch_rel_imm.i64"   if(A cmp B){PC +=(int64_t)(imm[62:0]*2);}
        Bits [11:8] Encode the comparison operation being performed: 
            A and B are different registers (register vs. register)
                X0XX eq           A==B
                X1XX neq          A!=B
                X2XX less.i64     (int64_t) A<B
                X3XX less.u64     (uint64_t) A<B
                X4XX lequal.i64   (int64_t) A<=B
                X5XX lequal.u64   (uint64_t) A<=B
                X6XX UNUSED
                X7XX UNUSED
                X8XX UNUSED
                X9XX UNUSED
                XAXX eq.f         (float) A==B
                XBXX neq.f        (float) A!=B
                XCXX less.f       (float) A<B
                XDXX greater.f    (float) A>B
                XEXX lequal.f     (float) A<=B
                XFXX gequal.f     (float) A>=B

            A and B are the same register (register vs. zero)
                X0XX eq_zero           A==0
                X1XX neq_zero          A!=0
                X2XX less_zero.i64     (int64_t) A<0
                X3XX UNUSED
                X4XX lequal_zero.i64   (int64_t) A<=0
                X5XX UNUSED
                X6XX greater_zero.i64  (int64_t) A>0
                X7XX gequal_zero.i64   (int64_t) A>=0
                X8XX UNUSED
                X9XX UNUSED
                XAXX eq_zero.f         (float) A==0
                XBXX neq_zero.f        (float) A!=0
                XCXX less_zero.f       (float) A<0
                XDXX greater_zero.f    (float) A>0
                XEXX lequal_zero.f     (float) A<=0
                XFXX gequal_zero.f     (float) A>=0
        Bits [7:4] Encode the index of register B
        Bits [3:0] Encode the index of register A

One Operand Class:   [ 3:0 A  ] [ 15:4 op2 [ values 0x010-0x0FF]] 
    push_ops: strop(SP,A) SP+=sizeof(ldop):
        010x push.u8  *(uint8_t*) (mem+SP) = A; SP+=1 
        011x push.u16 *(uint16_t*)(mem+SP) = A; SP+=2
        012x push.u32 *(uint32_t*)(mem+SP) = A; SP+=4
        013x push.u64 *(uint64_t*)(mem+SP) = A; SP+=8

        014x unused
        015x unused
        016x unused
        017x unused
        018x unused

        019x push.f16  *(half*)(mem+SP)   = A; SP+=2
        01Ax push.f32  *(float*)(mem+SP)  = A; SP+=4
        01Bx push.f64  *(double*)(mem+SP) = A; SP+=8

        01Cx unused
        01Dx unused
        01Ex unused
        01Fx unused

    pop_ops: SP-=sizeof(ldop) A= ldop(SP):
        020x pop.u8  SP-=1; A=*(uint8_t*) (mem+SP); 
        021x pop.u16 SP-=2; A=*(uint16_t*)(mem+SP);
        022x pop.u32 SP-=4; A=*(uint32_t*)(mem+SP);
        023x pop.u64 SP-=8; A=*(uint64_t*)(mem+SP);

        024x pop.i8  SP-=1; A=*(int8_t*) (mem+SP); 
        025x pop.i16 SP-=2; A=*(int16_t*)(mem+SP);
        026x pop.i32 SP-=4; A=*(int32_t*)(mem+SP);
        027x pop.i64 SP-=8; A=*(int64_t*)(mem+SP);

        028x unused
        029x pop.f16  SP-=2; A=*(half*)(mem+SP);
        02Ax pop.f32  SP-=4; A=*(float*)(mem+SP);
        02Bx pop.f64  SP-=8; A=*(double*)(mem+SP);

        02Cx unused
        02Dx unused
        02Ex unused
        02Fx unused
    load_immediate: A = ldop(PC) PC+=sizeof(ldop); PC is pre-incrememented to advance instruction stream before operation
        030x ldim.u8  A=*(uint8_t*) (mem+PC); PC+= 1
        031x ldim.u16 A=*(uint16_t*)(mem+PC); PC+= 2
        032x ldim.u32 A=*(uint32_t*)(mem+PC); PC+= 4
        033x ldim.u64 A=*(uint64_t*)(mem+PC); PC+= 8

        034x ldim.i8  A=*(int8_t*) (mem+PC); PC+= 1
        035x ldim.i16 A=*(int16_t*)(mem+PC); PC+= 2
        036x ldim.i32 A=*(int32_t*)(mem+PC); PC+= 4
        037x ldim.i64 A=*(int64_t*)(mem+PC); PC+= 8

        038x unused
        039x ldim.f16  A=*(half*)(mem+PC);   PC+= 2
        03Ax ldim.f32  A=*(float*)(mem+PC);  PC+= 4
        03Bx ldim.f64  A=*(double*)(mem+PC); PC+= 8

        03Cx unused
        03Dx unused
        03Ex unused
        03Fx unused
    special_reg_op [A=i0-i15]
        040x getpc : mov A = PC
        041x getsp : mov A = SP
        042x getlr : mov A = LR
        043x unused
        044x unused
        045x setsp : mov SP = A 
        046x setlr : mov LR = A 
        047x unused
        048x unused
        049x unused
        04Ax-04Fx unused
    call_ops:
        050x call_indirect            mem[SP]=LR;LR=PC+2; SP+=8; PC = A;
        051x call_relative_indirect   mem[SP]=LR;LR=PC+2; SP+=8; PC += A;
        052x branch_indirect          PC = A;
        053x branch_relative_indirect PC += A;
        0540-05FF unused
    add_sub_pow2_constant: [A=i0-i15]
        060x inc_2 : add A+=2
        061x inc_4 : add A+=4
        062x inc_8: add A+=8
        063x inc_16 : add A+=16
        064x inc_32 : add A+=32
        065x inc_64 : add A+=64
        066x inc_128 : add A+=128
        067x inc_256 : add A+=256
        068x dec_2 : sub A-=2
        069x dec_4 : sub A-=4
        06Ax dec_8 : sub A-=8
        06Bx dec_16 : sub A-=16
        06Cx dec_32 : sub A-=32
        06Dx dec_64 : sub A-=64
        06Ex dec_128 : sub A-=128
        06Fx dec_256 : sub A-=256
    add_sub_special_constant [A=i0-i15]
        070x inc_3 : add A+=3
        071x inc_5 : add A+=5
        072x inc_10 : add A+=10
        073x inc_20 : add A+=20
        074x inc_50 : add A+=50
        075x inc_100 : add A+=100
        076x inc_1000 : add A+=1000
        077x inc_10000 : add A+=10000
        078x dec_3 : sub A-=3
        079x dec_5 : sub A-=5
        07Ax dec_10 : sub A-=10
        07Bx dec_20 : sub A-=20
        07Cx dec_50 : sub A-=50
        07Dx dec_100 : sub A-=100
        07Ex dec_1000 : sub A-=1000
        07Fx dec_10000 : sub A-=10000

    add_sub_float_constant: [A=f0-f15]
        080x inc_0.25 : add.f A+=0.25
        081x inc_0.5 : add.f A+=0.5
        082x inc_1.0 : add.f A+=1.0
        083x inc_0.1 : add.f A+=0.1
        084x inc_2.0 : add.f A+=2.0
        085x inc_4.0 : add.f A+=4.0
        086x inc_10.0 : add.f A+=10.
        087x inc_100.0 : add.f A+=100.
        088x dec_0.25 : sub.f A-=0.25
        089x dec_0.5 : sub.f A-=0.5
        08Ax dec_1.0 : sub.f A-=1.0
        08Bx dec_0.1 : sub.f A-=0.1
        08Cx dec_2.0 : sub.f A-=2.0
        08Dx dec_4.0 : sub.f A-=4.0
        08Ex dec_10.0 : sub.f A-=10.
        08Fx dec_100.0 : sub.f A-=100.

    fp_special_functions: [A=f0-f15]
        090x cos.f   A = cos(A)
        091x sin.f   A = sin(A)
        092x tan.f   A = tan(A)
        093x sqrt.f  A = sqrt(A)
        094x rsqrt.f A = 1.0/sqrt(A)
        095x rcp.f   A = 1.0/A
        096x exp.f   A = e^x
        097x ln.f    A = ln(x)
        098x log10.f A = log10(x)
        099x-09Fx unused


    supervisor_hypervisor_call
        0A00-0CFF SVC opcode[11:0]-0x0A00
        0D00-0FFF HVC opcode[11:0]-0x0D00
 
No operand Class:    [ 15:0 op2 [ values 0x0000-0x00FF]] 
    flow_control:
        0000 illegal
        0001 call_imm.u16          mem[SP]=LR; LR=PC+2; SP+=8; PC =*(uint16_t*)(mem+PC);
        0002 call_imm.u32          mem[SP]=LR; LR=PC+4; SP+=8; PC =*(uint32_t*)(mem+PC);
        0003 call_imm.u64          mem[SP]=LR; LR=PC+8; SP+=8; PC =*(uint64_t*)(mem+PC);
        0004 call_rel_imm.i16      mem[SP]=LR; LR=PC+2; SP+=8; PC +=*(int16_t*)(mem+PC);
        0005 call_rel_imm.i32      mem[SP]=LR; LR=PC+4; SP+=8; PC +=*(int32_t*)(mem+PC);
        0006 call_rel_imm.i64      mem[SP]=LR; LR=PC+8; SP+=8; PC +=*(int64_t*)(mem+PC);
        0007 svc_return            svc_return;
        0008 hvc_return            hvc_return;
        0009 branch_imm.u16        PC =*(uint16_t*)(mem+PC);
        000A branch_imm.u32        PC =*(uint32_t*)(mem+PC);
        000B branch_imm.u64        PC =*(uint64_t*)(mem+PC);
        000C branch_rel_imm.i16    PC +=*(int16_t*)(mem+PC);
        000D branch_rel_imm.i32    PC +=*(int32_t*)(mem+PC);
        000E branch_rel_imm.i64    PC +=*(int64_t*)(mem+PC);
        000F return                PC = LR; SP-=8; LR=mem[SP] 

        0010-001F unused

    coprocessor_sync:
        0020-002F wait.cpc_reg cp_id0-cp_idF (waits for coprocessor register writeback)
        0030-003F wait.cpc_mem cp_id0-cp_idF (waits for coprocessor register and memory writeback)

    special_ops:
        0040 breakpoint       SW Breakpoint
        0041 wait.interrupt   Wait for interrupt
        
    0042-00FF unused
